<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Journal Entry - My Journal</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
        }
    </script>
    <style>
        .recording {
            animation: pulse 2s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        /* Touch target improvements */
        .touch-target {
            min-height: 44px;
            min-width: 44px;
        }
        
        /* Mobile-specific styles */
        @media (max-width: 640px) {
            .mobile-stack {
                flex-direction: column;
                align-items: stretch;
            }
            
            .mobile-stack > * {
                margin-bottom: 0.75rem;
            }
            
            .mobile-stack > *:last-child {
                margin-bottom: 0;
            }
        }
    </style>
</head>
<body class="bg-gray-50 dark:bg-gray-900 min-h-screen transition-colors">
    <div class="container mx-auto px-3 sm:px-4 py-4 sm:py-8 max-w-4xl">
        <!-- Header -->
        <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-6 sm:mb-8 space-y-4 sm:space-y-0 relative">
            <button id="backBtn" class="touch-target flex items-center justify-center sm:justify-start text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 transition-colors bg-white/50 dark:bg-gray-800/50 rounded-xl px-4 py-2 sm:bg-transparent">
                <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path>
                </svg>
                Home
            </button>
            <div class="text-center">
                <h1 class="text-2xl sm:text-3xl font-light text-gray-800 dark:text-gray-100">Journal Entry</h1>
                <p class="text-gray-600 dark:text-gray-400 text-sm" id="entryDate"></p>
            </div>
            
            <!-- Music Control - Top Right Corner -->
            <div class="absolute top-0 right-0">
                <button id="musicToggle" class="touch-target p-2 bg-white/70 dark:bg-gray-800/70 text-gray-700 dark:text-gray-300 rounded-xl hover:bg-white dark:hover:bg-gray-700 transition-all duration-200 shadow-sm border border-gray-200 dark:border-gray-600 flex flex-col items-center space-y-1" title="Play ambient music">
                    <svg id="musicIcon" class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <!-- Play icon (default state) -->
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 5v14l11-7z"></path>
                    </svg>
                    <span id="musicLabel" class="text-xs font-medium text-gray-600 dark:text-gray-400">Play Music</span>
                </button>
            </div>
        </div>

        <!-- Mood Display (if available) -->
        <div id="moodDisplay" class="bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-3 sm:p-4 mb-4 sm:mb-6 hidden">
            <div class="flex items-center justify-center space-x-3">
                <span class="text-sm text-gray-600 dark:text-gray-400">Today's mood:</span>
                <span id="todayMoodEmoji" class="text-xl sm:text-2xl"></span>
                <span id="todayMoodText" class="text-sm font-medium text-gray-800 dark:text-gray-200"></span>
            </div>
        </div>

        <!-- Journal Entry Form -->
        <div class="bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-4 sm:p-6">
            <form id="entryForm" class="space-y-4 sm:space-y-6">
                <!-- Summary Input -->
                <div>
                    <label for="entrySummary" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        One-line summary <span class="text-gray-500">(Optional)</span>
                    </label>
                    <input 
                        type="text" 
                        id="entrySummary" 
                        placeholder="What happened today in one sentence..."
                        class="w-full px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 dark:bg-gray-700 dark:text-gray-100 dark:placeholder-gray-400 text-base"
                    >
                </div>

                <!-- Main Content Area -->
                <div>
                    <label for="entryContent" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        Your thoughts and reflections
                    </label>
                    <textarea 
                        id="entryContent" 
                        rows="12"
                        placeholder="Start writing your journal entry here..."
                        class="w-full px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 resize-none dark:bg-gray-700 dark:text-gray-100 dark:placeholder-gray-400 text-base"
                        required
                    ></textarea>
                </div>

                <!-- 💬 Talk to me Section -->
                <div class="border-t border-gray-200 dark:border-gray-600 pt-4 sm:pt-6">
                    <h3 class="text-lg font-medium text-gray-800 dark:text-gray-100 mb-4 flex flex-col sm:flex-row sm:items-center">
                        <span class="flex items-center">
                            💬 Talk to me
                        </span>
                        <span class="text-sm text-gray-500 dark:text-gray-400 font-normal mt-1 sm:mt-0 sm:ml-2">Voice Assistant (Auto-detects language)</span>
                    </h3>

                    <!-- Voice Recording Controls -->
                    <div class="mobile-stack flex items-center space-x-4 mb-4">
                        <button type="button" id="recordBtn" class="touch-target px-4 sm:px-6 py-3 bg-red-600 dark:bg-red-700 text-white rounded-xl hover:bg-red-700 dark:hover:bg-red-600 transition-colors font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial">
                            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                            </svg>
                            <span id="recordBtnText">Start Recording</span>
                        </button>
                        
                        <div id="recordingStatus" class="text-sm text-gray-600 dark:text-gray-400 hidden">
                            <div class="flex items-center space-x-2">
                                <div class="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
                                <span>Recording... <span id="recordingTime">0:00</span></span>
                            </div>
                        </div>
                        
                        <div id="processingStatus" class="text-sm text-blue-600 dark:text-blue-400 hidden">
                            <div class="flex items-center space-x-2">
                                <div class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-600 dark:border-blue-400"></div>
                                <span>Processing with AI...</span>
                            </div>
                        </div>
                    </div>

                    <!-- Voice Instructions -->
                    <div class="bg-blue-50 dark:bg-blue-900 border border-blue-200 dark:border-blue-700 rounded-xl p-4">
                        <h4 class="font-medium text-blue-800 dark:text-blue-200 mb-2">How it works:</h4>
                        <ul class="text-sm text-blue-700 dark:text-blue-300 space-y-1">
                            <li>• Speak naturally in any language - AI will automatically detect it</li>
                            <li>• Your speech will be transcribed exactly as spoken</li>
                            <li>• Translations provided if speaking in non-English languages</li>
                            <li>• Perfect for quick voice journaling or when typing is inconvenient</li>
                            <li>• Just pure transcription - your authentic voice in text</li>
                            <li>• <strong>Music automatically pauses during recording for clear audio</strong></li>
                        </ul>
                    </div>
                </div>

                <!-- Action Buttons -->
                <div class="flex flex-col sm:flex-row space-y-3 sm:space-y-0 sm:space-x-4">
                    <button 
                        type="submit" 
                        class="touch-target flex-1 bg-blue-600 dark:bg-blue-700 text-white py-3 rounded-xl hover:bg-blue-700 dark:hover:bg-blue-600 transition-colors font-medium"
                    >
                        Save Entry
                    </button>
                    <button 
                        type="button" 
                        id="deleteBtn" 
                        class="touch-target px-6 py-3 bg-red-600 dark:bg-red-700 text-white rounded-xl hover:bg-red-700 dark:hover:bg-red-600 transition-colors font-medium hidden"
                    >
                        Delete
                    </button>
                </div>
            </form>
        </div>

        <!-- Writing Tips -->
        <div class="mt-4 sm:mt-6 bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-4 sm:p-6">
            <h3 class="text-lg font-medium text-gray-800 dark:text-gray-100 mb-3">Writing Tips</h3>
            <div class="grid grid-cols-1 sm:grid-cols-2 gap-4 text-sm text-gray-600 dark:text-gray-400">
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Reflect on your day</h4>
                    <p>What went well? What challenges did you face?</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Express your emotions</h4>
                    <p>How are you feeling? What emotions came up?</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Use voice assistant</h4>
                    <p>Speak naturally in your preferred language for easy journaling</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Be honest</h4>
                    <p>This is your safe space - write authentically</p>
                </div>
            </div>
        </div>
        
        <!-- Mobile Bottom Padding -->
        <div class="h-4 sm:h-0"></div>
    </div>

    <!-- Hidden Audio Element -->
    <audio id="backgroundMusic" loop preload="auto" style="display: none;">
        <source src="https://www.soundjay.com/misc/sounds-of-nature/rain-02.mp3" type="audio/mpeg">
    </audio>

    <script>
        class JournalEntry {
            constructor() {
                this.currentDate = this.getDateFromURL() || new Date().toISOString().split('T')[0];
                this.entries = this.loadEntries();
                this.moods = this.loadMoods();
                this.moodLabels = ['Sad', 'Frustrated', 'Confused', 'Anxious', 'Neutral', 'Happy', 'Content', 'Excited'];
                this.moodEmojis = ['😭', '😡', '🫤', '😨', '😐', '😄', '😌', '🤩'];
                this.autoSaveTimer = null;
                this.isRecording = false;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.recordingTimer = null;
                this.recordingStartTime = null;
                this.musicWasPausedForRecording = false;
                // WARNING: In production, use environment variables or backend API
                this.GEMINI_API_KEY = 'AIzaSyC_ZRimxlh9GdFO5RdfKh0CBkC57Esr5NI';
                this.init();
            }

            init() {
                // Initialize dark mode
                this.initDarkMode();
                
                this.setupDateDisplay();
                this.loadExistingEntry();
                this.displayMood();
                this.bindEvents();
                this.setupVoiceRecording();
                this.setupMobileOptimizations();
                this.setupMusicPlayer();
                document.getElementById('entryContent').focus();
            }

            initDarkMode() {
                const isDarkMode = localStorage.getItem('darkMode') === 'true';
                if (isDarkMode) {
                    document.documentElement.classList.add('dark');
                }
            }

            setupDateDisplay() {
                const date = new Date(this.currentDate);
                const options = { 
                    weekday: 'long', 
                    year: 'numeric', 
                    month: 'long', 
                    day: 'numeric' 
                };
                document.getElementById('entryDate').textContent = date.toLocaleDateString('en-US', options);
            }

            getDateFromURL() {
                const urlParams = new URLSearchParams(window.location.search);
                return urlParams.get('date');
            }

            loadExistingEntry() {
                const existingEntry = this.entries[this.currentDate];
                if (existingEntry) {
                    const lines = existingEntry.split('\n');
                    const summary = lines[0].startsWith('**Summary:**') ? lines[0].replace('**Summary:** ', '') : '';
                    const content = lines.slice(summary ? 2 : 0).join('\n'); // Skip summary and empty line if present
                    
                    document.getElementById('entrySummary').value = summary;
                    document.getElementById('entryContent').value = content;
                    document.getElementById('deleteBtn').classList.remove('hidden');
                }
            }

            displayMood() {
                const todaysMood = this.moods[this.currentDate];
                if (todaysMood !== undefined) {
                    document.getElementById('moodDisplay').classList.remove('hidden');
                    document.getElementById('todayMoodEmoji').textContent = this.moodEmojis[todaysMood];
                    document.getElementById('todayMoodText').textContent = this.moodLabels[todaysMood];
                }
            }

            bindEvents() {
                document.getElementById('backBtn').addEventListener('click', (e) => {
                    this.autoSaveBeforeLeaving();
                    window.location.href = 'index.html';
                });

                document.getElementById('entryForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.saveEntry();
                });

                document.getElementById('deleteBtn').addEventListener('click', () => {
                    this.deleteEntry();
                });

                // Auto-save draft
                let autoSaveTimeout;
                const autoSave = () => {
                    clearTimeout(autoSaveTimeout);
                    autoSaveTimeout = setTimeout(() => {
                        this.saveDraft();
                    }, 2000);
                };

                document.getElementById('entryContent').addEventListener('input', autoSave);
                document.getElementById('entrySummary').addEventListener('input', autoSave);

                // Auto-save when leaving the page
                window.addEventListener('beforeunload', (e) => {
                    this.autoSaveBeforeLeaving();
                });

                // Keyboard shortcuts
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'Escape') {
                        this.autoSaveBeforeLeaving();
                        window.location.href = 'index.html';
                    }
                    if ((e.ctrlKey || e.metaKey) && e.key === 's') {
                        e.preventDefault();
                        this.saveEntry();
                    }
                });
            }

            autoSaveBeforeLeaving() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                // Only auto-save if there's actual content
                if (content && content.length > 0) {
                    let finalEntry = '';
                    if (summary) {
                        finalEntry = `**Summary:** ${summary}\n\n${content}`;
                    } else {
                        finalEntry = content;
                    }

                    this.entries[this.currentDate] = finalEntry;
                    this.saveEntries();
                    
                    // Remove any draft since we saved the actual entry
                    this.removeDraft();
                }
            }

            setupVoiceRecording() {
                const recordBtn = document.getElementById('recordBtn');
                
                // Enhanced mobile touch support
                const handleRecordingToggle = (e) => {
                    e.preventDefault(); // Prevent default touch behaviors
                    
                    if (this.isRecording) {
                        this.stopRecording();
                    } else {
                        this.startRecording();
                    }
                };
                
                // Add both click and touch events for maximum compatibility
                recordBtn.addEventListener('click', handleRecordingToggle);
                recordBtn.addEventListener('touchend', handleRecordingToggle);
                
                // Prevent double-firing of events on mobile
                recordBtn.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                });
            }

            setupMobileOptimizations() {
                // Prevent zoom on input focus on iOS
                if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                    const viewport = document.querySelector('meta[name="viewport"]');
                    if (viewport) {
                        viewport.content = 'width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no';
                    }
                }

                // Improve scrolling on mobile
                document.querySelectorAll('textarea, select').forEach(element => {
                    element.style.webkitOverflowScrolling = 'touch';
                });

                // Handle mobile keyboard better
                if (window.visualViewport) {
                    window.visualViewport.addEventListener('resize', () => {
                        // Adjust layout when mobile keyboard appears
                        const vh = window.visualViewport.height * 0.01;
                        document.documentElement.style.setProperty('--vh', `${vh}px`);
                    });
                }

                // Add haptic feedback for recording button on supported devices
                const recordBtn = document.getElementById('recordBtn');
                if (recordBtn && 'vibrate' in navigator) {
                    recordBtn.addEventListener('touchstart', () => {
                        // Small vibration feedback when touching record button
                        navigator.vibrate && navigator.vibrate(10);
                    });
                }

                // Prevent accidental text selection during recording
                document.addEventListener('selectstart', (e) => {
                    if (this.isRecording) {
                        e.preventDefault();
                    }
                });
            }

            setupMusicPlayer() {
                const musicToggle = document.getElementById('musicToggle');
                const musicIcon = document.getElementById('musicIcon');
                const musicLabel = document.getElementById('musicLabel');
                this.isPlaying = false;
                this.audioContext = null;
                this.oscillators = [];
                this.currentTrack = null;
                this.musicParams = null;

                // Load calm music parameters from Gemini API
                this.loadCalmMusicParameters();

                // Enhanced mobile and desktop event handling
                const handleMusicToggle = async (e) => {
                    e.preventDefault(); // Prevent default behaviors
                    
                    try {
                        if (this.isPlaying) {
                            this.pauseMusic();
                        } else {
                            await this.playMusic();
                        }
                    } catch (error) {
                        console.error('Music toggle error:', error);
                        alert('Audio not available. Please try again or check your device audio settings.');
                    }
                };

                // Add both click and touch events for maximum mobile compatibility
                musicToggle.addEventListener('click', handleMusicToggle);
                musicToggle.addEventListener('touchend', (e) => {
                    e.preventDefault();
                    handleMusicToggle(e);
                });

                // Prevent double-firing on mobile
                musicToggle.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                    // Visual feedback on touch
                    musicToggle.style.transform = 'scale(0.95)';
                });

                musicToggle.addEventListener('touchcancel', (e) => {
                    musicToggle.style.transform = 'scale(1)';
                });

                // Reset scale after touch
                musicToggle.addEventListener('touchend', (e) => {
                    setTimeout(() => {
                        musicToggle.style.transform = 'scale(1)';
                    }, 100);
                });

                // Initialize with play state
                this.updateMusicButton('play');
            }

            async loadCalmMusicParameters() {
                try {
                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${this.GEMINI_API_KEY}`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            contents: [{
                                parts: [{
                                    text: `Generate parameters for creating calm, ambient background music for focused journaling. Create a peaceful soundscape that changes gradually over time.

Please provide musical parameters for Web Audio API:

STYLE: [calm ambient, nature-inspired, or minimalist piano]
TEMPO: [very slow, 40-60 BPM for relaxation]
KEY: [peaceful keys like C major, F major, or A minor]
HARMONY: [simple, consonant chord progressions]
RHYTHM: [gentle, minimal percussion or none]
TEXTURES: [soft pads, gentle arpeggios, nature sounds]
EVOLUTION: [how the music should change over 5-10 minutes]

Focus on:
- Very calm and non-distracting
- Suitable for concentration and reflection
- Gradual evolution to keep it interesting
- Therapeutic and peaceful qualities
- No sudden changes or harsh sounds

Format as a JSON-like structure for easy parsing.`
                                }]
                            }],
                            generationConfig: {
                                temperature: 0.8,
                                maxOutputTokens: 500,
                            }
                        })
                    });

                    if (response.ok) {
                        const data = await response.json();
                        this.musicParams = data.candidates[0].content.parts[0].text;
                        console.log('Calm music parameters from Gemini:', this.musicParams);
                    }
                } catch (error) {
                    console.error('Error loading calm music parameters:', error);
                }
            }

            async playMusic() {
                try {
                    console.log('Attempting to start ambient music...');

                    // Create or get existing audio context
                    if (!this.audioContext) {
                        // Use webkit prefix for older mobile browsers
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        console.log('Created new AudioContext, state:', this.audioContext.state);
                    }

                    // Handle suspended audio context (common on mobile)
                    if (this.audioContext.state === 'suspended') {
                        console.log('Resuming suspended AudioContext...');
                        await this.audioContext.resume();
                        console.log('AudioContext resumed, new state:', this.audioContext.state);
                    }

                    // Double-check that audio context is running
                    if (this.audioContext.state !== 'running') {
                        // Try to start it again after a small delay
                        await new Promise(resolve => setTimeout(resolve, 100));
                        if (this.audioContext.state === 'suspended') {
                            await this.audioContext.resume();
                        }
                    }

                    // If still not running, show a helpful message
                    if (this.audioContext.state !== 'running') {
                        throw new Error(`AudioContext state: ${this.audioContext.state}. Please try tapping the button again.`);
                    }

                    console.log('AudioContext ready, creating music...');

                    // Create calm ambient music
                    this.createLofiHouseMusic(this.audioContext);
                    this.isPlaying = true;
                    
                    // Update button to pause state
                    this.updateMusicButton('pause');
                    
                    console.log('Ambient music started successfully');

                } catch (error) {
                    console.error('Error starting music:', error);
                    
                    // Provide user-friendly error messages
                    let userMessage = 'Could not start ambient music. ';
                    if (error.message.includes('AudioContext')) {
                        userMessage += 'Please try tapping the play button again. Some devices require a second tap to enable audio.';
                    } else if (error.name === 'NotAllowedError') {
                        userMessage += 'Audio playback was blocked. Please enable audio in your browser settings.';
                    } else if (error.name === 'NotSupportedError') {
                        userMessage += 'Audio playback is not supported on this device/browser.';
                    } else {
                        userMessage += `Error: ${error.message}`;
                    }
                    
                    alert(userMessage);
                    
                    // Reset button state
                    this.updateMusicButton('play');
                }
            }

            pauseMusic(isAutomatic = false) {
                // Stop all oscillators completely
                this.oscillators.forEach(osc => {
                    try {
                        osc.stop();
                    } catch (e) {
                        // Oscillator might already be stopped
                    }
                });
                this.oscillators = [];
                this.isPlaying = false;
                
                // Clear any pending timeouts to prevent new sounds from starting
                if (this.audioContext) {
                    this.audioContext.suspend();
                }
                
                // Update button to play state
                if (!isAutomatic) {
                    // Only update button state if manually stopped
                    this.updateMusicButton('play');
                }
                
                console.log(isAutomatic ? 'Music automatically paused for recording' : 'Music manually stopped');
            }

            updateMusicButton(state) {
                const musicToggle = document.getElementById('musicToggle');
                const musicIcon = document.getElementById('musicIcon');
                const musicLabel = document.getElementById('musicLabel');

                if (state === 'play') {
                    // Play state styling
                    musicToggle.className = 'touch-target p-2 bg-white/70 dark:bg-gray-800/70 text-gray-700 dark:text-gray-300 rounded-xl hover:bg-green-50 dark:hover:bg-green-900/20 hover:text-green-600 dark:hover:text-green-400 transition-all duration-200 shadow-sm border border-gray-200 dark:border-gray-600 flex flex-col items-center space-y-1';
                    musicToggle.title = 'Play ambient music';
                    
                    // Play icon
                    musicIcon.innerHTML = `
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 5v14l11-7z"></path>
                    `;
                    
                    if (musicLabel) {
                        musicLabel.textContent = 'Play Music';
                        musicLabel.className = 'text-xs font-medium text-gray-600 dark:text-gray-400';
                    }
                } else {
                    // Pause state styling
                    musicToggle.className = 'touch-target p-2 bg-green-500 dark:bg-green-600 text-white rounded-xl hover:bg-green-600 dark:hover:bg-green-700 transition-all duration-200 shadow-lg border border-green-400 dark:border-green-500 flex flex-col items-center space-y-1';
                    musicToggle.title = 'Pause ambient music';
                    
                    // Pause icon
                    musicIcon.innerHTML = `
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 9v6m4-6v6"></path>
                    `;
                    
                    if (musicLabel) {
                        musicLabel.textContent = 'Playing...';
                        musicLabel.className = 'text-xs font-medium text-white';
                    }
                }
            }

            async startRecording() {
                try {
                    // Automatically pause music to avoid interference with voice recording
                    if (this.isPlaying) {
                        console.log('Pausing music for voice recording...');
                        this.pauseMusic(true); // Pass true to indicate automatic pausing
                        this.musicWasPausedForRecording = true; // Track that we paused it
                        
                        // Show user feedback about music being paused
                        const musicLabel = document.getElementById('musicLabel');
                        if (musicLabel) {
                            musicLabel.textContent = 'Paused for Recording';
                            musicLabel.className = 'text-xs font-medium text-orange-600 dark:text-orange-400';
                        }
                    } else {
                        this.musicWasPausedForRecording = false;
                    }

                    // Check for mobile browser compatibility
                    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                        alert('Voice recording is not supported on this device/browser. Please try using Chrome or Safari.');
                        return;
                    }

                    // Use flexible constraints that work on all mobile devices
                    let constraints = {
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    };

                    // Try with basic audio constraints first (more compatible)
                    let stream;
                    try {
                        stream = await navigator.mediaDevices.getUserMedia(constraints);
                    } catch (constraintError) {
                        console.log('Trying with basic audio constraints due to:', constraintError);
                        // Fallback to very basic constraints for maximum compatibility
                        constraints = { audio: true };
                        stream = await navigator.mediaDevices.getUserMedia(constraints);
                    }
                    
                    // Determine the best audio format for the device
                    let mimeType = 'audio/webm';
                    let options = {};
                    
                    // Check supported formats in order of preference
                    if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                        mimeType = 'audio/webm;codecs=opus';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                        mimeType = 'audio/mp4';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/mp4;codecs=mp4a.40.2')) {
                        mimeType = 'audio/mp4;codecs=mp4a.40.2';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
                        mimeType = 'audio/ogg;codecs=opus';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                        mimeType = 'audio/webm';
                        options = { mimeType: mimeType };
                    } else {
                        // For maximum compatibility, let the browser choose
                        console.log('Using browser default audio format');
                        mimeType = 'audio/webm'; // Default fallback
                        options = {}; // Let browser decide
                    }

                    console.log('Using MIME type:', mimeType, 'with options:', options);
                    
                    // Create MediaRecorder with flexible options
                    try {
                        this.mediaRecorder = new MediaRecorder(stream, options);
                    } catch (recorderError) {
                        console.log('Trying MediaRecorder without options due to:', recorderError);
                        // Ultimate fallback - let browser choose everything
                        this.mediaRecorder = new MediaRecorder(stream);
                        mimeType = 'audio/webm'; // Assume webm as default
                    }
                    
                    const audioChunks = [];

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                            console.log('Audio chunk received, size:', event.data.size);
                        }
                    };

                    this.mediaRecorder.onstop = async () => {
                        // Get actual MIME type from the recorded data
                        const actualMimeType = audioChunks.length > 0 ? audioChunks[0].type || mimeType : mimeType;
                        const audioBlob = new Blob(audioChunks, { type: actualMimeType });
                        console.log('Audio recording complete. Size:', audioBlob.size, 'bytes, MIME type:', actualMimeType);
                        
                        if (audioBlob.size === 0) {
                            alert('No audio was recorded. Please try again and make sure to speak clearly and allow microphone access.');
                            // Reset music button state if recording failed
                            this.resetMusicButtonAfterRecording();
                            return;
                        }
                        
                        // Minimum size check (audio should be at least a few KB)
                        if (audioBlob.size < 1000) {
                            alert('Recording too short or empty. Please try speaking for at least 2-3 seconds.');
                            // Reset music button state if recording failed
                            this.resetMusicButtonAfterRecording();
                            return;
                        }
                        
                        await this.processAudioWithGemini(audioBlob);
                        
                        // Stop all tracks to release microphone
                        stream.getTracks().forEach(track => track.stop());
                        
                        // Reset music button state after successful recording
                        this.resetMusicButtonAfterRecording();
                    };

                    this.mediaRecorder.onerror = (event) => {
                        console.error('MediaRecorder error:', event.error);
                        alert('Recording error occurred. Please try again.');
                        stream.getTracks().forEach(track => track.stop());
                        
                        // Reset music button state if recording failed
                        this.resetMusicButtonAfterRecording();
                    };

                    // Start recording with more frequent data capture for mobile reliability
                    try {
                        this.mediaRecorder.start(250); // Every 250ms
                    } catch (startError) {
                        console.log('Trying start without timeslice:', startError);
                        this.mediaRecorder.start(); // No timeslice for compatibility
                    }
                    
                    this.isRecording = true;
                    this.updateRecordingUI();
                    this.startRecordingTimer();
                    
                    console.log('Recording started successfully');

                } catch (error) {
                    console.error('Error starting recording:', error);
                    
                    // Reset music button state if recording failed to start
                    this.resetMusicButtonAfterRecording();
                    
                    let errorMessage = 'Could not start recording. ';
                    if (error.name === 'NotAllowedError') {
                        errorMessage += 'Please allow microphone access in your browser settings and try again. On iOS, make sure Safari has microphone permission.';
                    } else if (error.name === 'NotFoundError') {
                        errorMessage += 'No microphone found on this device.';
                    } else if (error.name === 'NotSupportedError') {
                        errorMessage += 'Voice recording is not supported on this browser. Try using Chrome on Android or Safari on iOS.';
                    } else if (error.name === 'NotReadableError') {
                        errorMessage += 'Microphone is being used by another application. Please close other apps and try again.';
                    } else if (error.name === 'OverconstrainedError') {
                        errorMessage += 'Audio constraints not supported. The app will try again with basic settings.';
                        // You could retry here with even more basic constraints
                    } else {
                        errorMessage += `Error: ${error.message}. Please check your microphone permissions and try again.`;
                    }
                    
                    alert(errorMessage);
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    this.updateRecordingUI();
                    this.stopRecordingTimer();
                }
            }

            resetMusicButtonAfterRecording() {
                // Reset the music button text and state after recording is complete
                const musicLabel = document.getElementById('musicLabel');
                if (musicLabel && !this.isPlaying) {
                    musicLabel.textContent = 'Play Music';
                    musicLabel.className = 'text-xs font-medium text-gray-600 dark:text-gray-400';
                }
                
                // Don't automatically restart music - let user choose
                this.musicWasPausedForRecording = false;
            }

            startRecordingTimer() {
                this.recordingStartTime = Date.now();
                this.recordingTimer = setInterval(() => {
                    const elapsed = Math.floor((Date.now() - this.recordingStartTime) / 1000);
                    const minutes = Math.floor(elapsed / 60);
                    const seconds = elapsed % 60;
                    document.getElementById('recordingTime').textContent = 
                        `${minutes}:${seconds.toString().padStart(2, '0')}`;
                }, 1000);
            }

            stopRecordingTimer() {
                if (this.recordingTimer) {
                    clearInterval(this.recordingTimer);
                    this.recordingTimer = null;
                }
            }

            updateRecordingUI() {
                const recordBtn = document.getElementById('recordBtn');
                const recordBtnText = document.getElementById('recordBtnText');
                const recordingStatus = document.getElementById('recordingStatus');

                if (this.isRecording) {
                    recordBtn.className = 'touch-target px-4 sm:px-6 py-3 bg-gray-600 dark:bg-gray-700 text-white rounded-xl hover:bg-gray-700 dark:hover:bg-gray-600 transition-colors font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial';
                    recordBtnText.textContent = 'Stop Recording';
                    recordingStatus.classList.remove('hidden');
                    
                    // Update recording status to mention music if it was paused
                    const recordingTimeSpan = document.getElementById('recordingTime');
                    if (this.musicWasPausedForRecording) {
                        const statusText = recordingStatus.querySelector('span');
                        if (statusText) {
                            statusText.innerHTML = `Recording... <span id="recordingTime">${recordingTimeSpan ? recordingTimeSpan.textContent : '0:00'}</span> <span class="text-orange-300">(Music paused)</span>`;
                        }
                    }
                } else {
                    recordBtn.className = 'touch-target px-4 sm:px-6 py-3 bg-red-600 dark:bg-red-700 text-white rounded-xl hover:bg-red-700 dark:hover:bg-red-600 transition-colors font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial';
                    recordBtnText.textContent = 'Start Recording';
                    recordingStatus.classList.add('hidden');
                }
            }

            async processAudioWithGemini(audioBlob) {
                const processingStatus = document.getElementById('processingStatus');
                processingStatus.classList.remove('hidden');

                try {
                    // Convert audio blob to base64
                    const base64Audio = await this.blobToBase64(audioBlob);
                    
                    // Get the correct MIME type for the audio
                    let mimeType = audioBlob.type || 'audio/webm';
                    
                    // Map mobile browser MIME types to API-compatible formats
                    if (mimeType.includes('mp4') || mimeType.includes('m4a')) {
                        mimeType = 'audio/mp4';
                    } else if (mimeType.includes('ogg')) {
                        mimeType = 'audio/ogg';
                    } else if (mimeType.includes('wav')) {
                        mimeType = 'audio/wav';
                    } else {
                        // Default to webm for unknown formats
                        mimeType = 'audio/webm';
                    }
                    
                    console.log('Audio blob size:', audioBlob.size, 'bytes');
                    console.log('Original MIME type:', audioBlob.type);
                    console.log('API MIME type:', mimeType);
                    
                    const requestBody = {
                        contents: [{
                            parts: [
                                {
                                    text: `You are a transcription assistant. Please transcribe the audio exactly as spoken. 

- If the audio is in English, just provide the transcription
- If the audio is in another language, provide both the original transcription and English translation
- Keep it natural and exactly as the person spoke
- Do not add any commentary, analysis, or extra formatting

Format your response as:
TRANSCRIPTION: [exactly what was said]
TRANSLATION: [English translation if needed, otherwise "N/A"]`
                                },
                                {
                                    inline_data: {
                                        mime_type: mimeType,
                                        data: base64Audio.split(',')[1]
                                    }
                                }
                            ]
                        }],
                        generationConfig: {
                            temperature: 0.1,
                            maxOutputTokens: 300,
                        }
                    };

                    console.log('Sending request to Gemini API...');
                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${this.GEMINI_API_KEY}`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify(requestBody)
                    });

                    if (!response.ok) {
                        const errorText = await response.text();
                        console.error('API Response Error:', response.status, errorText);
                        throw new Error(`API Error ${response.status}: ${errorText}`);
                    }

                    const data = await response.json();
                    console.log('API Response:', data);
                    
                    if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
                        throw new Error('Invalid response from API - no content generated');
                    }
                    
                    const aiResponse = data.candidates[0].content.parts[0].text;
                    console.log('AI Response:', aiResponse);
                    
                    // Parse the response
                    const transcriptionMatch = aiResponse.match(/TRANSCRIPTION:\s*(.+?)(?:\n|TRANSLATION:)/s);
                    const translationMatch = aiResponse.match(/TRANSLATION:\s*(.+?)(?:\n|$)/s);
                    
                    const transcription = transcriptionMatch ? transcriptionMatch[1].trim() : 'Could not transcribe audio';
                    const translation = translationMatch ? translationMatch[1].trim() : '';
                    
                    // Add transcription to journal entry
                    let finalText = transcription;
                    if (translation && translation !== 'N/A' && translation.toLowerCase() !== transcription.toLowerCase()) {
                        finalText += ` (${translation})`;
                    }
                    
                    // Provide feedback about successful transcription
                    console.log('Transcription successful:', finalText);
                    this.addVoiceContentToEntry(finalText);

                } catch (error) {
                    console.error('Error processing audio with Gemini:', error);
                    
                    let userMessage = 'Error processing audio. ';
                    
                    if (error.message.includes('API Error 400')) {
                        userMessage += 'The audio format may not be supported by the AI service. Try recording again or speaking more clearly.';
                    } else if (error.message.includes('API Error 401') || error.message.includes('API Error 403')) {
                        userMessage += 'Authentication error with the AI service. Please contact support.';
                    } else if (error.message.includes('API Error 429')) {
                        userMessage += 'Too many requests to the AI service. Please wait a moment and try again.';
                    } else if (error.message.includes('Invalid response')) {
                        userMessage += 'The AI could not process your audio. Please try speaking more clearly and ensure good audio quality.';
                    } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
                        userMessage += 'Network error. Please check your internet connection and try again.';
                    } else if (error.message.includes('Failed to fetch')) {
                        userMessage += 'Connection error. Please check your internet connection and try again.';
                    } else {
                        userMessage += `Error: ${error.message}. Please try again or check your microphone.`;
                    }
                    
                    alert(userMessage);
                } finally {
                    processingStatus.classList.add('hidden');
                }
            }

            saveSentiment(sentiment) {
                const sentiments = this.loadSentiments();
                sentiments[this.currentDate] = sentiment;
                localStorage.setItem('journalSentiments', JSON.stringify(sentiments));
            }

            loadSentiments() {
                const stored = localStorage.getItem('journalSentiments');
                return stored ? JSON.parse(stored) : {};
            }

            addVoiceContentToEntry(aiResponse) {
                const entryContent = document.getElementById('entryContent');
                const currentContent = entryContent.value;
                
                // Add separator if there's existing content
                const separator = currentContent.trim() ? '\n\n---\n\n' : '';
                const newContent = currentContent + separator + aiResponse + '\n\n';
                
                entryContent.value = newContent;
                
                // Auto-focus at the end
                entryContent.focus();
                entryContent.setSelectionRange(entryContent.value.length, entryContent.value.length);
                
                // Trigger auto-save
                entryContent.dispatchEvent(new Event('input'));
            }

            blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result);
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }

            saveEntry() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                if (!content) {
                    alert('Please write something in your journal entry.');
                    return;
                }

                let finalEntry = '';
                if (summary) {
                    finalEntry = `**Summary:** ${summary}\n\n${content}`;
                } else {
                    finalEntry = content;
                }

                this.entries[this.currentDate] = finalEntry;
                this.saveEntries();

                // Remove any draft
                this.removeDraft();

                // Show success message and redirect
                alert('Journal entry saved successfully!');
                window.location.href = 'index.html';
            }

            saveDraft() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                if (content || summary) {
                    const draft = { summary, content, date: this.currentDate };
                    localStorage.setItem('journalDraft', JSON.stringify(draft));
                }
            }

            removeDraft() {
                localStorage.removeItem('journalDraft');
            }

            deleteEntry() {
                if (confirm('Are you sure you want to delete this journal entry? This action cannot be undone.')) {
                    delete this.entries[this.currentDate];
                    this.saveEntries();
                    this.removeDraft();
                    window.location.href = 'index.html';
                }
            }

            loadEntries() {
                const stored = localStorage.getItem('journalEntries');
                return stored ? JSON.parse(stored) : {};
            }

            loadMoods() {
                const stored = localStorage.getItem('journalMoods');
                return stored ? JSON.parse(stored) : {};
            }

            saveEntries() {
                localStorage.setItem('journalEntries', JSON.stringify(this.entries));
            }

            createLofiHouseMusic(audioContext) {
                // Create calm, evolving ambient music
                
                // 1. Gentle Pad Sounds
                this.createCalmPads(audioContext);
                
                // 2. Soft Arpeggios
                this.createSoftArpeggios(audioContext);
                
                // 3. Nature-inspired Textures
                this.createNatureTextures(audioContext);
                
                // 4. Minimal Percussion (very soft)
                this.createMinimalPercussion(audioContext);
                
                // 5. Schedule music evolution every 2-3 minutes
                this.scheduleMusicEvolution(audioContext);
            }

            createCalmPads(audioContext) {
                // Very calm and peaceful chord progressions
                const calmChords = [
                    [261, 329, 392], // C major
                    [293, 369, 440], // D minor
                    [174, 220, 261], // F major
                    [196, 247, 294], // G major
                ];
                
                let chordIndex = 0;
                
                const playCalm = () => {
                    if (!this.isPlaying || !audioContext || audioContext.state !== 'running') return;
                    
                    try {
                        const chord = calmChords[chordIndex];
                        
                        chord.forEach((freq, i) => {
                            const oscillator = audioContext.createOscillator();
                            const gainNode = audioContext.createGain();
                            const filter = audioContext.createBiquadFilter();
                            
                            oscillator.type = 'sine';
                            oscillator.frequency.setValueAtTime(freq, audioContext.currentTime);
                            oscillator.detune.setValueAtTime((Math.random() - 0.5) * 3, audioContext.currentTime);
                            
                            filter.type = 'lowpass';
                            filter.frequency.setValueAtTime(800, audioContext.currentTime);
                            filter.Q.setValueAtTime(0.5, audioContext.currentTime);
                            
                            gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                            gainNode.gain.linearRampToValueAtTime(0.015, audioContext.currentTime + 2);
                            gainNode.gain.linearRampToValueAtTime(0.01, audioContext.currentTime + 8);
                            
                            oscillator.connect(filter);
                            filter.connect(gainNode);
                            gainNode.connect(audioContext.destination);
                            
                            oscillator.start();
                            this.oscillators.push(oscillator);
                        });
                        
                        chordIndex = (chordIndex + 1) % calmChords.length;
                        
                        if (this.isPlaying && audioContext.state === 'running') {
                            setTimeout(playCalm, 8000); // Very slow progression
                        }
                    } catch (error) {
                        console.error('Error in createCalmPads:', error);
                    }
                };
                
                setTimeout(playCalm, 500);
            }

            createSoftArpeggios(audioContext) {
                const pentatonic = [261, 293, 329, 392, 440]; // C pentatonic scale
                let noteIndex = 0;
                
                const playArpeggio = () => {
                    if (!this.isPlaying || !audioContext || audioContext.state !== 'running') return;
                    
                    try {
                        const oscillator = audioContext.createOscillator();
                        const gainNode = audioContext.createGain();
                        const filter = audioContext.createBiquadFilter();
                        
                        oscillator.type = 'triangle';
                        oscillator.frequency.setValueAtTime(pentatonic[noteIndex] * 2, audioContext.currentTime);
                        
                        filter.type = 'lowpass';
                        filter.frequency.setValueAtTime(1200, audioContext.currentTime);
                        filter.Q.setValueAtTime(1, audioContext.currentTime);
                        
                        gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                        gainNode.gain.linearRampToValueAtTime(0.008, audioContext.currentTime + 0.1);
                        gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 2);
                        
                        oscillator.connect(filter);
                        filter.connect(gainNode);
                        gainNode.connect(audioContext.destination);
                        
                        oscillator.start();
                        oscillator.stop(audioContext.currentTime + 2);
                        this.oscillators.push(oscillator);
                        
                        noteIndex = (noteIndex + 1) % pentatonic.length;
                        
                        if (this.isPlaying && audioContext.state === 'running') {
                            setTimeout(playArpeggio, 1500 + Math.random() * 1000); // Irregular timing
                        }
                    } catch (error) {
                        console.error('Error in createSoftArpeggios:', error);
                    }
                };
                
                setTimeout(playArpeggio, 3000);
            }

            createNatureTextures(audioContext) {
                // Gentle wind-like textures
                const createWind = () => {
                    if (!this.isPlaying || !audioContext || audioContext.state !== 'running') return;
                    
                    try {
                        const bufferSize = 4096;
                        const buffer = audioContext.createBuffer(1, bufferSize, audioContext.sampleRate);
                        const output = buffer.getChannelData(0);
                        
                        for (let i = 0; i < bufferSize; i++) {
                            output[i] = (Math.random() * 2 - 1) * 0.02;
                        }
                        
                        const noise = audioContext.createBufferSource();
                        noise.buffer = buffer;
                        
                        const filter = audioContext.createBiquadFilter();
                        filter.type = 'bandpass';
                        filter.frequency.setValueAtTime(400 + Math.random() * 200, audioContext.currentTime);
                        filter.Q.setValueAtTime(0.5, audioContext.currentTime);
                        
                        const gainNode = audioContext.createGain();
                        gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                        gainNode.gain.linearRampToValueAtTime(0.003, audioContext.currentTime + 3);
                        gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 8);
                        
                        noise.connect(filter);
                        filter.connect(gainNode);
                        gainNode.connect(audioContext.destination);
                        
                        noise.start();
                        noise.stop(audioContext.currentTime + 8);
                        
                        if (this.isPlaying && audioContext.state === 'running') {
                            setTimeout(createWind, 10000 + Math.random() * 5000);
                        }
                    } catch (error) {
                        console.error('Error in createNatureTextures:', error);
                    }
                };
                
                setTimeout(createWind, 5000);
            }

            createMinimalPercussion(audioContext) {
                // Very soft, minimal percussion
                const createSoftClick = () => {
                    if (!this.isPlaying || !audioContext || audioContext.state !== 'running') return;
                    
                    try {
                        const oscillator = audioContext.createOscillator();
                        const gainNode = audioContext.createGain();
                        const filter = audioContext.createBiquadFilter();
                        
                        oscillator.type = 'sine';
                        oscillator.frequency.setValueAtTime(800, audioContext.currentTime);
                        oscillator.frequency.exponentialRampToValueAtTime(200, audioContext.currentTime + 0.05);
                        
                        filter.type = 'highpass';
                        filter.frequency.setValueAtTime(1000, audioContext.currentTime);
                        
                        gainNode.gain.setValueAtTime(0.002, audioContext.currentTime);
                        gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 0.1);
                        
                        oscillator.connect(filter);
                        filter.connect(gainNode);
                        gainNode.connect(audioContext.destination);
                        
                        oscillator.start();
                        oscillator.stop(audioContext.currentTime + 0.1);
                        this.oscillators.push(oscillator);
                        
                        if (this.isPlaying && audioContext.state === 'running') {
                            setTimeout(createSoftClick, 4000 + Math.random() * 8000); // Very sparse
                        }
                    } catch (error) {
                        console.error('Error in createMinimalPercussion:', error);
                    }
                };
                
                setTimeout(createSoftClick, 15000);
            }

            scheduleMusicEvolution(audioContext) {
                // Change the music style every 2-3 minutes for variety
                const evolveMusic = () => {
                    if (!this.isPlaying || !audioContext || audioContext.state !== 'running') return;
                    
                    try {
                        // Request new music parameters from Gemini
                        this.loadCalmMusicParameters().then(() => {
                            console.log('Music evolved with new parameters');
                        }).catch(error => {
                            console.error('Error evolving music:', error);
                        });
                        
                        if (this.isPlaying && audioContext.state === 'running') {
                            setTimeout(evolveMusic, 120000 + Math.random() * 60000); // 2-3 minutes
                        }
                    } catch (error) {
                        console.error('Error in scheduleMusicEvolution:', error);
                    }
                };
                
                setTimeout(evolveMusic, 120000); // First evolution after 2 minutes
            }
        }

        const journalEntry = new JournalEntry();
    </script>
</body>
</html> 