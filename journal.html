<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Journal Entry - My Journal</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            darkMode: 'class',
        }
    </script>
    <style>
        .recording {
            animation: pulse 2s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        /* Touch target improvements */
        .touch-target {
            min-height: 44px;
            min-width: 44px;
        }
        
        /* Mobile-specific styles */
        @media (max-width: 640px) {
            .mobile-stack {
                flex-direction: column;
                align-items: stretch;
            }
            
            .mobile-stack > * {
                margin-bottom: 0.75rem;
            }
            
            .mobile-stack > *:last-child {
                margin-bottom: 0;
            }
        }
    </style>
</head>
<body class="bg-gray-50 dark:bg-gray-900 min-h-screen transition-colors">
    <div class="container mx-auto px-3 sm:px-4 py-4 sm:py-8 max-w-4xl">
        <!-- Header -->
        <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-6 sm:mb-8 space-y-4 sm:space-y-0">
            <button id="backBtn" class="touch-target flex items-center justify-center sm:justify-start text-gray-600 dark:text-gray-400 hover:text-gray-800 dark:hover:text-gray-200 transition-colors bg-white/50 dark:bg-gray-800/50 rounded-xl px-4 py-2 sm:bg-transparent">
                <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path>
                </svg>
                Home
            </button>
            <div class="text-center">
                <h1 class="text-2xl sm:text-3xl font-light text-gray-800 dark:text-gray-100">Journal Entry</h1>
                <p class="text-gray-600 dark:text-gray-400 text-sm" id="entryDate"></p>
            </div>
        </div>

        <!-- Mood Display (if available) -->
        <div id="moodDisplay" class="bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-3 sm:p-4 mb-4 sm:mb-6 hidden">
            <div class="flex items-center justify-center space-x-3">
                <span class="text-sm text-gray-600 dark:text-gray-400">Today's mood:</span>
                <span id="todayMoodEmoji" class="text-xl sm:text-2xl"></span>
                <span id="todayMoodText" class="text-sm font-medium text-gray-800 dark:text-gray-200"></span>
            </div>
        </div>

        <!-- Journal Entry Form -->
        <div class="bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-4 sm:p-6">
            <form id="entryForm" class="space-y-4 sm:space-y-6">
                <!-- Summary Input -->
                <div>
                    <label for="entrySummary" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        One-line summary <span class="text-gray-500">(Optional)</span>
                    </label>
                    <input 
                        type="text" 
                        id="entrySummary" 
                        placeholder="What happened today in one sentence..."
                        class="w-full px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 dark:bg-gray-700 dark:text-gray-100 dark:placeholder-gray-400 text-base"
                    >
                </div>

                <!-- Main Content Area -->
                <div>
                    <label for="entryContent" class="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                        Your thoughts and reflections
                    </label>
                    <textarea 
                        id="entryContent" 
                        rows="12"
                        placeholder="Start writing your journal entry here..."
                        class="w-full px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 resize-none dark:bg-gray-700 dark:text-gray-100 dark:placeholder-gray-400 text-base"
                        required
                    ></textarea>
                </div>

                <!-- ðŸ¤– Smart AI Assistant Section -->
                <div class="border-t border-gray-200 dark:border-gray-600 pt-4 sm:pt-6">
                    <h3 class="text-lg font-medium text-gray-800 dark:text-gray-100 mb-4 flex flex-col sm:flex-row sm:items-center">
                        <span class="flex items-center">
                            ðŸ¤– Smart AI Journal Assistant
                        </span>
                        <span class="text-sm text-gray-500 dark:text-gray-400 font-normal mt-1 sm:mt-0 sm:ml-2">Intelligent conversation & auto-correction</span>
                    </h3>

                    <!-- Voice Recording Controls -->
                    <div class="mobile-stack flex items-center space-x-4 mb-4">
                        <button type="button" id="recordBtn" class="touch-target px-4 sm:px-6 py-3 bg-gradient-to-r from-purple-600 to-blue-600 dark:from-purple-700 dark:to-blue-700 text-white rounded-xl hover:from-purple-700 hover:to-blue-700 dark:hover:from-purple-600 dark:hover:to-blue-600 transition-all duration-200 font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial shadow-lg">
                            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                            </svg>
                            <span id="recordBtnText">Talk to AI Assistant</span>
                        </button>
                        
                        <div id="recordingStatus" class="text-sm text-gray-600 dark:text-gray-400 hidden">
                            <div class="flex items-center space-x-2">
                                <div class="w-2 h-2 bg-purple-500 rounded-full animate-pulse"></div>
                                <span>Listening... <span id="recordingTime">0:00</span></span>
                            </div>
                        </div>
                        
                        <div id="processingStatus" class="text-sm text-blue-600 dark:text-blue-400 hidden">
                            <div class="flex items-center space-x-2">
                                <div class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-600 dark:border-blue-400"></div>
                                <span>AI is thinking...</span>
                            </div>
                        </div>
                    </div>

                    <!-- AI Conversation History -->
                    <div id="conversationHistory" class="space-y-3 mb-4 max-h-96 overflow-y-auto"></div>

                    <!-- AI Assistant Instructions -->
                    <div class="bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-900/30 dark:to-blue-900/30 border border-purple-200 dark:border-purple-700 rounded-xl p-4">
                        <h4 class="font-medium text-purple-800 dark:text-purple-200 mb-2 flex items-center">
                            <span class="mr-2">âœ¨</span>
                            Your Smart Assistant Features:
                        </h4>
                        <ul class="text-sm text-purple-700 dark:text-purple-300 space-y-1">
                            <li>â€¢ <strong>Auto-corrects</strong> speech mistakes and improves clarity</li>
                            <li>â€¢ <strong>Asks follow-up questions</strong> based on your responses</li>
                            <li>â€¢ <strong>Engages naturally</strong> about your day and feelings</li>
                            <li>â€¢ <strong>Multi-language support</strong> with intelligent translation</li>
                            <li>â€¢ <strong>Emotional awareness</strong> and empathetic responses</li>
                            <li>â€¢ <strong>Memory</strong> of your conversation context</li>
                        </ul>
                        <div class="mt-3 text-xs text-purple-600 dark:text-purple-400">
                            ðŸ’¡ Tip: Just start talking naturally - "How was my day..." or "I'm feeling..." and the AI will guide the conversation!
                        </div>
                    </div>
                </div>

                <!-- Action Buttons -->
                <div class="flex flex-col sm:flex-row space-y-3 sm:space-y-0 sm:space-x-4">
                    <button 
                        type="submit" 
                        class="touch-target flex-1 bg-blue-600 dark:bg-blue-700 text-white py-3 rounded-xl hover:bg-blue-700 dark:hover:bg-blue-600 transition-colors font-medium"
                    >
                        Save Entry
                    </button>
                    <button 
                        type="button" 
                        id="deleteBtn" 
                        class="touch-target px-6 py-3 bg-red-600 dark:bg-red-700 text-white rounded-xl hover:bg-red-700 dark:hover:bg-red-600 transition-colors font-medium hidden"
                    >
                        Delete
                    </button>
                </div>
            </form>
        </div>

        <!-- Writing Tips -->
        <div class="mt-4 sm:mt-6 bg-white dark:bg-gray-800 rounded-xl sm:rounded-lg shadow-sm p-4 sm:p-6">
            <h3 class="text-lg font-medium text-gray-800 dark:text-gray-100 mb-3">Writing Tips</h3>
            <div class="grid grid-cols-1 sm:grid-cols-2 gap-4 text-sm text-gray-600 dark:text-gray-400">
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Reflect on your day</h4>
                    <p>What went well? What challenges did you face?</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Express your emotions</h4>
                    <p>How are you feeling? What emotions came up?</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Use voice assistant</h4>
                    <p>Speak naturally in your preferred language for easy journaling</p>
                </div>
                <div>
                    <h4 class="font-medium text-gray-800 dark:text-gray-200 mb-1">Be honest</h4>
                    <p>This is your safe space - write authentically</p>
                </div>
            </div>
        </div>
        
        <!-- Mobile Bottom Padding -->
        <div class="h-4 sm:h-0"></div>
    </div>

    <!-- Hidden Audio Element -->
    <audio id="backgroundMusic" loop preload="auto" style="display: none;">
        <source src="https://www.soundjay.com/misc/sounds-of-nature/rain-02.mp3" type="audio/mpeg">
    </audio>

    <script>
        class JournalEntry {
            constructor() {
                this.currentDate = this.getDateFromURL() || new Date().toISOString().split('T')[0];
                this.entries = this.loadEntries();
                this.moods = this.loadMoods();
                this.moodLabels = ['Sad', 'Frustrated', 'Confused', 'Anxious', 'Neutral', 'Happy', 'Content', 'Excited'];
                this.moodEmojis = ['ðŸ˜­', 'ðŸ˜¡', 'ðŸ«¤', 'ðŸ˜¨', 'ðŸ˜', 'ðŸ˜„', 'ðŸ˜Œ', 'ðŸ¤©'];
                this.autoSaveTimer = null;
                this.isRecording = false;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.recordingTimer = null;
                this.recordingStartTime = null;
                // WARNING: In production, use environment variables or backend API
                this.GEMINI_API_KEY = 'AIzaSyC_ZRimxlh9GdFO5RdfKh0CBkC57Esr5NI';
                
                // Smart Assistant properties
                this.conversationHistory = [];
                this.conversationContext = '';
                this.userProfile = this.loadUserProfile();
                this.isFirstInteraction = true;
                
                this.init();
            }

            init() {
                // Initialize dark mode
                this.initDarkMode();
                
                this.setupDateDisplay();
                this.loadExistingEntry();
                this.displayMood();
                this.loadConversationHistory(); // Load previous conversation
                this.bindEvents();
                this.setupVoiceRecording();
                this.setupMobileOptimizations();
                document.getElementById('entryContent').focus();
            }

            initDarkMode() {
                const isDarkMode = localStorage.getItem('darkMode') === 'true';
                if (isDarkMode) {
                    document.documentElement.classList.add('dark');
                }
            }

            setupDateDisplay() {
                const date = new Date(this.currentDate);
                const options = { 
                    weekday: 'long', 
                    year: 'numeric', 
                    month: 'long', 
                    day: 'numeric' 
                };
                document.getElementById('entryDate').textContent = date.toLocaleDateString('en-US', options);
            }

            getDateFromURL() {
                const urlParams = new URLSearchParams(window.location.search);
                return urlParams.get('date');
            }

            loadExistingEntry() {
                const existingEntry = this.entries[this.currentDate];
                if (existingEntry) {
                    const lines = existingEntry.split('\n');
                    const summary = lines[0].startsWith('**Summary:**') ? lines[0].replace('**Summary:** ', '') : '';
                    const content = lines.slice(summary ? 2 : 0).join('\n'); // Skip summary and empty line if present
                    
                    document.getElementById('entrySummary').value = summary;
                    document.getElementById('entryContent').value = content;
                    document.getElementById('deleteBtn').classList.remove('hidden');
                }
            }

            displayMood() {
                const todaysMood = this.moods[this.currentDate];
                if (todaysMood !== undefined) {
                    document.getElementById('moodDisplay').classList.remove('hidden');
                    document.getElementById('todayMoodEmoji').textContent = this.moodEmojis[todaysMood];
                    document.getElementById('todayMoodText').textContent = this.moodLabels[todaysMood];
                }
            }

            bindEvents() {
                document.getElementById('backBtn').addEventListener('click', (e) => {
                    this.autoSaveBeforeLeaving();
                    window.location.href = 'index.html';
                });

                document.getElementById('entryForm').addEventListener('submit', (e) => {
                    e.preventDefault();
                    this.saveEntry();
                });

                document.getElementById('deleteBtn').addEventListener('click', () => {
                    this.deleteEntry();
                });

                // Auto-save draft
                let autoSaveTimeout;
                const autoSave = () => {
                    clearTimeout(autoSaveTimeout);
                    autoSaveTimeout = setTimeout(() => {
                        this.saveDraft();
                    }, 2000);
                };

                document.getElementById('entryContent').addEventListener('input', autoSave);
                document.getElementById('entrySummary').addEventListener('input', autoSave);

                // Auto-save when leaving the page
                window.addEventListener('beforeunload', (e) => {
                    this.autoSaveBeforeLeaving();
                });

                // Keyboard shortcuts
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'Escape') {
                        this.autoSaveBeforeLeaving();
                        window.location.href = 'index.html';
                    }
                    if ((e.ctrlKey || e.metaKey) && e.key === 's') {
                        e.preventDefault();
                        this.saveEntry();
                    }
                });
            }

            autoSaveBeforeLeaving() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                // Only auto-save if there's actual content
                if (content && content.length > 0) {
                    let finalEntry = '';
                    if (summary) {
                        finalEntry = `**Summary:** ${summary}\n\n${content}`;
                    } else {
                        finalEntry = content;
                    }

                    this.entries[this.currentDate] = finalEntry;
                    this.saveEntries();
                    
                    // Remove any draft since we saved the actual entry
                    this.removeDraft();
                }
            }

            setupVoiceRecording() {
                const recordBtn = document.getElementById('recordBtn');
                
                // Enhanced mobile touch support
                const handleRecordingToggle = (e) => {
                    e.preventDefault(); // Prevent default touch behaviors
                    
                    if (this.isRecording) {
                        this.stopRecording();
                    } else {
                        this.startRecording();
                    }
                };
                
                // Add both click and touch events for maximum compatibility
                recordBtn.addEventListener('click', handleRecordingToggle);
                recordBtn.addEventListener('touchend', handleRecordingToggle);
                
                // Prevent double-firing of events on mobile
                recordBtn.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                });
            }

            setupMobileOptimizations() {
                // Prevent zoom on input focus on iOS
                if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                    const viewport = document.querySelector('meta[name="viewport"]');
                    if (viewport) {
                        viewport.content = 'width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no';
                    }
                }

                // Improve scrolling on mobile
                document.querySelectorAll('textarea, select').forEach(element => {
                    element.style.webkitOverflowScrolling = 'touch';
                });

                // Handle mobile keyboard better
                if (window.visualViewport) {
                    window.visualViewport.addEventListener('resize', () => {
                        // Adjust layout when mobile keyboard appears
                        const vh = window.visualViewport.height * 0.01;
                        document.documentElement.style.setProperty('--vh', `${vh}px`);
                    });
                }

                // Add haptic feedback for recording button on supported devices
                const recordBtn = document.getElementById('recordBtn');
                if (recordBtn && 'vibrate' in navigator) {
                    recordBtn.addEventListener('touchstart', () => {
                        // Small vibration feedback when touching record button
                        navigator.vibrate && navigator.vibrate(10);
                    });
                }

                // Prevent accidental text selection during recording
                document.addEventListener('selectstart', (e) => {
                    if (this.isRecording) {
                        e.preventDefault();
                    }
                });
            }

            async startRecording() {
                try {
                    // Check for mobile browser compatibility
                    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                        alert('Voice recording is not supported on this device/browser. Please try using Chrome or Safari.');
                        return;
                    }

                    // Use flexible constraints that work on all mobile devices
                    let constraints = {
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    };

                    // Try with basic audio constraints first (more compatible)
                    let stream;
                    try {
                        stream = await navigator.mediaDevices.getUserMedia(constraints);
                    } catch (constraintError) {
                        console.log('Trying with basic audio constraints due to:', constraintError);
                        // Fallback to very basic constraints for maximum compatibility
                        constraints = { audio: true };
                        stream = await navigator.mediaDevices.getUserMedia(constraints);
                    }
                    
                    // Determine the best audio format for the device
                    let mimeType = 'audio/webm';
                    let options = {};
                    
                    // Check supported formats in order of preference
                    if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                        mimeType = 'audio/webm;codecs=opus';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                        mimeType = 'audio/mp4';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/mp4;codecs=mp4a.40.2')) {
                        mimeType = 'audio/mp4;codecs=mp4a.40.2';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
                        mimeType = 'audio/ogg;codecs=opus';
                        options = { mimeType: mimeType };
                    } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                        mimeType = 'audio/webm';
                        options = { mimeType: mimeType };
                    } else {
                        // For maximum compatibility, let the browser choose
                        console.log('Using browser default audio format');
                        mimeType = 'audio/webm'; // Default fallback
                        options = {}; // Let browser decide
                    }

                    console.log('Using MIME type:', mimeType, 'with options:', options);
                    
                    // Create MediaRecorder with flexible options
                    try {
                        this.mediaRecorder = new MediaRecorder(stream, options);
                    } catch (recorderError) {
                        console.log('Trying MediaRecorder without options due to:', recorderError);
                        // Ultimate fallback - let browser choose everything
                        this.mediaRecorder = new MediaRecorder(stream);
                        mimeType = 'audio/webm'; // Assume webm as default
                    }
                    
                    const audioChunks = [];

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                            console.log('Audio chunk received, size:', event.data.size);
                        }
                    };

                    this.mediaRecorder.onstop = async () => {
                        // Get actual MIME type from the recorded data
                        const actualMimeType = audioChunks.length > 0 ? audioChunks[0].type || mimeType : mimeType;
                        const audioBlob = new Blob(audioChunks, { type: actualMimeType });
                        console.log('Audio recording complete. Size:', audioBlob.size, 'bytes, MIME type:', actualMimeType);
                        
                        if (audioBlob.size === 0) {
                            alert('No audio was recorded. Please try again and make sure to speak clearly and allow microphone access.');
                            return;
                        }
                        
                        // Minimum size check (audio should be at least a few KB)
                        if (audioBlob.size < 1000) {
                            alert('Recording too short or empty. Please try speaking for at least 2-3 seconds.');
                            return;
                        }
                        
                        await this.processAudioWithGemini(audioBlob);
                        
                        // Stop all tracks to release microphone
                        stream.getTracks().forEach(track => track.stop());
                    };

                    this.mediaRecorder.onerror = (event) => {
                        console.error('MediaRecorder error:', event.error);
                        alert('Recording error occurred. Please try again.');
                        stream.getTracks().forEach(track => track.stop());
                    };

                    // Start recording with more frequent data capture for mobile reliability
                    try {
                        this.mediaRecorder.start(250); // Every 250ms
                    } catch (startError) {
                        console.log('Trying start without timeslice:', startError);
                        this.mediaRecorder.start(); // No timeslice for compatibility
                    }
                    
                    this.isRecording = true;
                    this.updateRecordingUI();
                    this.startRecordingTimer();
                    
                    console.log('Recording started successfully');

                } catch (error) {
                    console.error('Error starting recording:', error);
                    
                    let errorMessage = 'Could not start recording. ';
                    if (error.name === 'NotAllowedError') {
                        errorMessage += 'Please allow microphone access in your browser settings and try again. On iOS, make sure Safari has microphone permission.';
                    } else if (error.name === 'NotFoundError') {
                        errorMessage += 'No microphone found on this device.';
                    } else if (error.name === 'NotSupportedError') {
                        errorMessage += 'Voice recording is not supported on this browser. Try using Chrome on Android or Safari on iOS.';
                    } else if (error.name === 'NotReadableError') {
                        errorMessage += 'Microphone is being used by another application. Please close other apps and try again.';
                    } else if (error.name === 'OverconstrainedError') {
                        errorMessage += 'Audio constraints not supported. The app will try again with basic settings.';
                        // You could retry here with even more basic constraints
                    } else {
                        errorMessage += `Error: ${error.message}. Please check your microphone permissions and try again.`;
                    }
                    
                    alert(errorMessage);
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    this.updateRecordingUI();
                    this.stopRecordingTimer();
                }
            }

            startRecordingTimer() {
                this.recordingStartTime = Date.now();
                this.recordingTimer = setInterval(() => {
                    const elapsed = Math.floor((Date.now() - this.recordingStartTime) / 1000);
                    const minutes = Math.floor(elapsed / 60);
                    const seconds = elapsed % 60;
                    document.getElementById('recordingTime').textContent = 
                        `${minutes}:${seconds.toString().padStart(2, '0')}`;
                }, 1000);
            }

            stopRecordingTimer() {
                if (this.recordingTimer) {
                    clearInterval(this.recordingTimer);
                    this.recordingTimer = null;
                }
            }

            updateRecordingUI() {
                const recordBtn = document.getElementById('recordBtn');
                const recordBtnText = document.getElementById('recordBtnText');
                const recordingStatus = document.getElementById('recordingStatus');

                if (this.isRecording) {
                    recordBtn.className = 'touch-target px-4 sm:px-6 py-3 bg-gray-600 dark:bg-gray-700 text-white rounded-xl hover:bg-gray-700 dark:hover:bg-gray-600 transition-colors font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial';
                    recordBtnText.textContent = 'Stop Talking';
                    recordingStatus.classList.remove('hidden');
                } else {
                    recordBtn.className = 'touch-target px-4 sm:px-6 py-3 bg-gradient-to-r from-purple-600 to-blue-600 dark:from-purple-700 dark:to-blue-700 text-white rounded-xl hover:from-purple-700 hover:to-blue-700 dark:hover:from-purple-600 dark:hover:to-blue-600 transition-all duration-200 font-medium flex items-center justify-center space-x-2 flex-1 sm:flex-initial shadow-lg';
                    recordBtnText.textContent = 'Talk to AI Assistant';
                    recordingStatus.classList.add('hidden');
                }
            }

            async processAudioWithGemini(audioBlob) {
                const processingStatus = document.getElementById('processingStatus');
                processingStatus.classList.remove('hidden');

                try {
                    // Convert audio blob to base64
                    const base64Audio = await this.blobToBase64(audioBlob);
                    
                    // Get the correct MIME type for the audio
                    let mimeType = audioBlob.type || 'audio/webm';
                    
                    // Map mobile browser MIME types to API-compatible formats
                    if (mimeType.includes('mp4') || mimeType.includes('m4a')) {
                        mimeType = 'audio/mp4';
                    } else if (mimeType.includes('ogg')) {
                        mimeType = 'audio/ogg';
                    } else if (mimeType.includes('wav')) {
                        mimeType = 'audio/wav';
                    } else {
                        // Default to webm for unknown formats
                        mimeType = 'audio/webm';
                    }
                    
                    console.log('Audio blob size:', audioBlob.size, 'bytes');
                    console.log('Processing with smart AI assistant...');
                    
                    // Build conversation context
                    let conversationContext = this.buildConversationContext();
                    
                    const requestBody = {
                        contents: [{
                            parts: [
                                {
                                    text: `You are an empathetic, intelligent journal assistant named Luna. Your role is to help users reflect on their day through natural conversation.

ðŸ§  CORE ABILITIES:
â€¢ Auto-correct speech recognition errors and improve clarity
â€¢ Ask thoughtful follow-up questions based on user responses
â€¢ Engage naturally about feelings, experiences, and emotions
â€¢ Provide emotional support and encouragement
â€¢ Help users explore their thoughts more deeply

ðŸ‘¤ USER CONTEXT:
${this.userProfile ? `User's name: ${this.userProfile.name}` : 'User name unknown'}
Current mood today: ${this.getCurrentMoodText()}
Date: ${new Date(this.currentDate).toDateString()}

ðŸ’¬ CONVERSATION CONTEXT:
${conversationContext}

ðŸŽ¯ YOUR RESPONSE APPROACH:
1. First, transcribe and auto-correct what the user said (fix grammar, clarity, remove filler words)
2. Respond empathetically to their content
3. Ask ONE thoughtful follow-up question that encourages deeper reflection
4. Keep responses warm, supportive, and natural (2-3 sentences max)
5. Adapt your questions based on their emotional state and what they've shared

ðŸ“ RESPONSE FORMAT:
CORRECTED_SPEECH: [Auto-corrected, polished version of what they said]
AI_RESPONSE: [Your empathetic response and thoughtful follow-up question]

Example:
If user says "um like today was... it was really hard you know"
CORRECTED_SPEECH: Today was really hard.
AI_RESPONSE: I can hear that today was tough for you. That takes strength to acknowledge. What was the most challenging part of your day that made it feel so difficult?

Be conversational, caring, and curious about their inner world.`
                                },
                                {
                                    inline_data: {
                                        mime_type: mimeType,
                                        data: base64Audio.split(',')[1]
                                    }
                                }
                            ]
                        }],
                        generationConfig: {
                            temperature: 0.8,
                            maxOutputTokens: 500,
                        }
                    };

                    console.log('Sending request to Gemini API...');
                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${this.GEMINI_API_KEY}`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify(requestBody)
                    });

                    if (!response.ok) {
                        const errorText = await response.text();
                        console.error('API Response Error:', response.status, errorText);
                        throw new Error(`API Error ${response.status}: ${errorText}`);
                    }

                    const data = await response.json();
                    console.log('API Response:', data);
                    
                    if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
                        throw new Error('Invalid response from API - no content generated');
                    }
                    
                    const aiResponse = data.candidates[0].content.parts[0].text;
                    console.log('AI Response:', aiResponse);
                    
                    // Parse the response
                    const correctedSpeechMatch = aiResponse.match(/CORRECTED_SPEECH:\s*(.+?)(?:\n|AI_RESPONSE:)/s);
                    const aiResponseMatch = aiResponse.match(/AI_RESPONSE:\s*(.+?)(?:\n|$)/s);
                    
                    const correctedSpeech = correctedSpeechMatch ? correctedSpeechMatch[1].trim() : 'I heard you speaking, but couldn\'t make out the words clearly.';
                    const assistantResponse = aiResponseMatch ? aiResponseMatch[1].trim() : 'I\'m here to listen. Could you tell me more about what\'s on your mind?';
                    
                    // Add to conversation history and display
                    this.addToConversationHistory('user', correctedSpeech);
                    this.addToConversationHistory('assistant', assistantResponse);
                    
                    // Add corrected speech to journal entry
                    this.addVoiceContentToEntry(correctedSpeech);
                    
                    console.log('Smart assistant interaction completed');

                } catch (error) {
                    console.error('Error processing audio with smart assistant:', error);
                    
                    let userMessage = 'I\'m having trouble understanding you right now. ';
                    
                    if (error.message.includes('API Error 400')) {
                        userMessage += 'Could you try speaking more clearly? I want to make sure I hear you properly.';
                    } else if (error.message.includes('API Error 401') || error.message.includes('API Error 403')) {
                        userMessage += 'There\'s a technical issue with my AI brain. Please try again in a moment.';
                    } else if (error.message.includes('API Error 429')) {
                        userMessage += 'I need a moment to process. Please wait a few seconds and talk to me again.';
                    } else if (error.message.includes('Invalid response')) {
                        userMessage += 'I couldn\'t process what you said. Try speaking a bit more slowly and clearly.';
                    } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
                        userMessage += 'I need an internet connection to understand you. Please check your connection.';
                    } else if (error.message.includes('Failed to fetch')) {
                        userMessage += 'I\'m having trouble connecting right now. Please check your internet and try again.';
                    } else {
                        userMessage += 'Something went wrong on my end. Please try talking to me again.';
                    }
                    
                    this.addToConversationHistory('assistant', userMessage);
                } finally {
                    processingStatus.classList.add('hidden');
                    this.isFirstInteraction = false;
                }
            }

            saveSentiment(sentiment) {
                const sentiments = this.loadSentiments();
                sentiments[this.currentDate] = sentiment;
                localStorage.setItem('journalSentiments', JSON.stringify(sentiments));
            }

            loadSentiments() {
                const stored = localStorage.getItem('journalSentiments');
                return stored ? JSON.parse(stored) : {};
            }

            addVoiceContentToEntry(aiResponse) {
                const entryContent = document.getElementById('entryContent');
                const currentContent = entryContent.value;
                
                // Only add to journal if it's substantial content (not just short responses)
                if (aiResponse.length > 10 && !aiResponse.toLowerCase().includes('could you') && !aiResponse.toLowerCase().includes('try speaking')) {
                    // Add separator if there's existing content
                    const separator = currentContent.trim() ? '\n\n' : '';
                    const newContent = currentContent + separator + aiResponse;
                    
                    entryContent.value = newContent;
                    
                    // Auto-focus at the end
                    entryContent.focus();
                    entryContent.setSelectionRange(entryContent.value.length, entryContent.value.length);
                    
                    // Trigger auto-save
                    entryContent.dispatchEvent(new Event('input'));
                }
            }

            blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result);
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }

            saveEntry() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                if (!content) {
                    alert('Please write something in your journal entry.');
                    return;
                }

                let finalEntry = '';
                if (summary) {
                    finalEntry = `**Summary:** ${summary}\n\n${content}`;
                } else {
                    finalEntry = content;
                }

                this.entries[this.currentDate] = finalEntry;
                this.saveEntries();

                // Remove any draft
                this.removeDraft();

                // Show success message and redirect
                alert('Journal entry saved successfully!');
                window.location.href = 'index.html';
            }

            saveDraft() {
                const summary = document.getElementById('entrySummary').value.trim();
                const content = document.getElementById('entryContent').value.trim();

                if (content || summary) {
                    const draft = { summary, content, date: this.currentDate };
                    localStorage.setItem('journalDraft', JSON.stringify(draft));
                }
            }

            removeDraft() {
                localStorage.removeItem('journalDraft');
            }

            deleteEntry() {
                if (confirm('Are you sure you want to delete this journal entry? This action cannot be undone.')) {
                    delete this.entries[this.currentDate];
                    this.saveEntries();
                    this.removeDraft();
                    window.location.href = 'index.html';
                }
            }

            loadEntries() {
                const stored = localStorage.getItem('journalEntries');
                return stored ? JSON.parse(stored) : {};
            }

            loadMoods() {
                const stored = localStorage.getItem('journalMoods');
                return stored ? JSON.parse(stored) : {};
            }

            saveEntries() {
                localStorage.setItem('journalEntries', JSON.stringify(this.entries));
            }

            buildConversationContext() {
                if (this.conversationHistory.length === 0) {
                    return `This is the user's first interaction. Greet them warmly and ask how their day is going.`;
                }
                
                // Build context from recent conversation
                let context = 'Recent conversation:\n';
                const recentMessages = this.conversationHistory.slice(-6); // Last 6 messages
                recentMessages.forEach(msg => {
                    context += `${msg.role === 'user' ? 'User' : 'You'}: ${msg.message}\n`;
                });
                
                return context + '\nContinue the conversation naturally based on what the user just said.';
            }

            getCurrentMoodText() {
                const todaysMood = this.moods[this.currentDate];
                if (todaysMood !== undefined) {
                    return this.moodLabels[todaysMood] + ' ' + this.moodEmojis[todaysMood];
                }
                return 'Not set yet';
            }

            addToConversationHistory(role, message) {
                this.conversationHistory.push({
                    role: role,
                    message: message,
                    timestamp: new Date().toISOString()
                });
                
                // Keep only last 10 exchanges to avoid overwhelming the context
                if (this.conversationHistory.length > 20) {
                    this.conversationHistory = this.conversationHistory.slice(-20);
                }
                
                this.displayConversationHistory();
                this.saveConversationHistory();
            }

            displayConversationHistory() {
                const historyContainer = document.getElementById('conversationHistory');
                if (!historyContainer) return;
                
                if (this.conversationHistory.length === 0) {
                    historyContainer.innerHTML = '';
                    return;
                }
                
                historyContainer.innerHTML = this.conversationHistory.map(msg => {
                    const isUser = msg.role === 'user';
                    const time = new Date(msg.timestamp).toLocaleTimeString([], {hour: '2-digit', minute:'2-digit'});
                    
                    return `
                        <div class="flex ${isUser ? 'justify-end' : 'justify-start'} mb-3">
                            <div class="max-w-[80%] ${isUser ? 'order-2' : 'order-1'}">
                                <div class="flex items-center space-x-2 mb-1">
                                    <span class="text-xs text-gray-500 dark:text-gray-400">
                                        ${isUser ? 'You' : 'ðŸ¤– Luna'}
                                    </span>
                                    <span class="text-xs text-gray-400 dark:text-gray-500">${time}</span>
                                </div>
                                <div class="p-3 rounded-xl ${isUser 
                                    ? 'bg-gradient-to-r from-purple-500 to-blue-500 text-white rounded-br-sm' 
                                    : 'bg-gray-100 dark:bg-gray-700 text-gray-800 dark:text-gray-200 rounded-bl-sm'
                                } text-sm leading-relaxed">
                                    ${msg.message}
                                </div>
                            </div>
                        </div>
                    `;
                }).join('');
                
                // Auto-scroll to bottom
                setTimeout(() => {
                    historyContainer.scrollTop = historyContainer.scrollHeight;
                }, 100);
            }

            saveConversationHistory() {
                const storageKey = `conversation_${this.currentDate}`;
                localStorage.setItem(storageKey, JSON.stringify(this.conversationHistory));
            }

            loadConversationHistory() {
                const storageKey = `conversation_${this.currentDate}`;
                const stored = localStorage.getItem(storageKey);
                if (stored) {
                    this.conversationHistory = JSON.parse(stored);
                    this.displayConversationHistory();
                    this.isFirstInteraction = this.conversationHistory.length === 0;
                }
            }

            loadUserProfile() {
                const stored = localStorage.getItem('userProfile');
                return stored ? JSON.parse(stored) : null;
            }
        }

        const journalEntry = new JournalEntry();
    </script>
</body>
</html> 